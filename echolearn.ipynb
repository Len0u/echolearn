{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "662acf10",
   "metadata": {},
   "source": [
    "# Prototype: AI-Powered Study Assistant using Gemma 3n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "\n",
    "client = Client()\n",
    "model = \"gemma3n:e2b\"\n",
    "\n",
    "MAX_SECTION_LENGTH = 1500  # max chars per chunk\n",
    "OVERLAP_LENGTH = 200       # overlap chars between chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14ba85",
   "metadata": {},
   "source": [
    "### Preprocessing Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f0c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    return unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "def is_heading(line):\n",
    "    line = line.strip()\n",
    "\n",
    "    # Reject empty lines or bullet points\n",
    "    if not line or line.startswith((\"-\", \"*\", \"•\")):\n",
    "        return False\n",
    "\n",
    "    # Reject lines that are too long (likely paragraph)\n",
    "    if len(line) > 80:\n",
    "        return False\n",
    "\n",
    "    # Heuristic 1: Ends with colon or question mark\n",
    "    if line.endswith((':', '?')):\n",
    "        return True\n",
    "\n",
    "    # Heuristic 2: All uppercase or Title case (capitalized words)\n",
    "    if line.isupper():\n",
    "        return True\n",
    "\n",
    "    # Heuristic 3: Starts with capital letter, and has no ending punctuation (likely a title)\n",
    "    if re.match(r\"^[A-Z][\\w\\s\\-()]*$\", line):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def split_text_into_sections(text):\n",
    "    lines = text.splitlines()\n",
    "    sections = []\n",
    "    current_title = None\n",
    "    current_text = []\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        if not stripped:\n",
    "            continue\n",
    "\n",
    "        if is_heading(stripped):\n",
    "            # Save previous section\n",
    "            if current_title or current_text:\n",
    "                sections.append({\n",
    "                    \"title\": current_title or \"Untitled\",\n",
    "                    \"text\": \"\\n\".join(current_text).strip()\n",
    "                })\n",
    "            current_title = stripped\n",
    "            current_text = []\n",
    "        else:\n",
    "            current_text.append(stripped)\n",
    "\n",
    "    # Final section\n",
    "    if current_title or current_text:\n",
    "        sections.append({\n",
    "            \"title\": current_title or \"Untitled\",\n",
    "            \"text\": \"\\n\".join(current_text).strip()\n",
    "        })\n",
    "\n",
    "    # Optional: remove sections with no useful text\n",
    "    return [s for s in sections if s[\"text\"].strip()]\n",
    "\n",
    "def split_long_section(section, max_length=MAX_SECTION_LENGTH, overlap=OVERLAP_LENGTH):\n",
    "    text = section[\"text\"]\n",
    "    title = section[\"title\"]\n",
    "    chunks = []\n",
    "\n",
    "    start = 0\n",
    "    length = len(text)\n",
    "    while start < length:\n",
    "        end = start + max_length\n",
    "        if end >= length:\n",
    "            chunk_text = text[start:]\n",
    "            chunks.append({\"title\": title, \"text\": chunk_text.strip()})\n",
    "            break\n",
    "        else:\n",
    "            # Try to split at the last newline before max_length to avoid cutting mid sentence/line\n",
    "            split_pos = text.rfind(\"\\n\", start, end)\n",
    "            if split_pos == -1 or split_pos <= start:\n",
    "                split_pos = end  # no newline found, split hard at max_length\n",
    "\n",
    "            chunk_text = text[start:split_pos].strip()\n",
    "            chunks.append({\"title\": title, \"text\": chunk_text})\n",
    "\n",
    "            # Next start is split_pos minus overlap to keep some context\n",
    "            start = max(split_pos - overlap, start + 1)\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22494933",
   "metadata": {},
   "source": [
    "### Load and Prepare Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d3afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess\n",
    "with open(\"test.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    context = normalize(f.read())\n",
    "\n",
    "sections = split_text_into_sections(context)\n",
    "\n",
    "# Further split any too-long sections\n",
    "final_sections = []\n",
    "for sec in sections:\n",
    "    if len(sec[\"text\"]) > MAX_SECTION_LENGTH:\n",
    "        split_chunks = split_long_section(sec)\n",
    "        final_sections.extend(split_chunks)\n",
    "    else:\n",
    "        final_sections.append(sec)\n",
    "\n",
    "with open(\"sections.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sections, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Split into {len(sections)} sections.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba36b45",
   "metadata": {},
   "source": [
    "### LLM Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f366271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gemma_raw(prompt):\n",
    "    response = client.generate(model=model, prompt=prompt)\n",
    "    return response[\"response\"]\n",
    "\n",
    "def parse_sections_json(raw_response):\n",
    "    try:\n",
    "        # Remove ```json or ``` wrapper\n",
    "        cleaned = raw_response.strip()\n",
    "        if cleaned.startswith(\"```json\"):\n",
    "            cleaned = cleaned.removeprefix(\"```json\").removesuffix(\"```\").strip()\n",
    "        elif cleaned.startswith(\"```\"):\n",
    "            cleaned = cleaned.removeprefix(\"```\").removesuffix(\"```\").strip()\n",
    "\n",
    "        # Normalize all Unicode to standard ASCII equivalents\n",
    "        cleaned = unicodedata.normalize(\"NFKD\", cleaned).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "\n",
    "        # Replace smart quotes\n",
    "        cleaned = re.sub(r\"[“”]\", '\"', cleaned)\n",
    "        cleaned = re.sub(r\"[‘’]\", \"'\", cleaned)\n",
    "\n",
    "        # Escape inner newlines in text fields\n",
    "        cleaned = re.sub(r'\"text\":\\s*\"([\\s\\S]*?)\"', lambda m: f'\"text\": \"{m.group(1).replace(\"\\n\", \"\\\\n\")}\"', cleaned)\n",
    "\n",
    "        # Remove trailing commas before closing brackets\n",
    "        cleaned = re.sub(r\",\\s*]\", \"]\", cleaned)\n",
    "\n",
    "        return json.loads(cleaned)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse cleaned JSON: {e}\")\n",
    "        print(\"Raw response was:\\n\", raw_response)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a282fc30",
   "metadata": {},
   "source": [
    "### Quiz Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688fdb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "\n",
    "for section in sections:\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful study assistant. Given the following notes section, please:\n",
    "\n",
    "1. Summarize the key points briefly.\n",
    "2. Generate 3-5 quiz questions that test understanding of these key points.\n",
    "\n",
    "Return the output as a JSON object with the following format:\n",
    "\n",
    "{{\n",
    "  \"summary\": \"brief summary text here\",\n",
    "  \"questions\": [\n",
    "    \"Question 1?\",\n",
    "    \"Question 2?\",\n",
    "    ...\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Notes:\n",
    "{section['text']}\n",
    "\n",
    "Section title: {section['title']}\n",
    "\"\"\".strip()\n",
    "\n",
    "    response_text = ask_gemma_raw(prompt).strip()\n",
    "    print(response_text)\n",
    "    parsed = parse_sections_json(response_text)\n",
    "    \n",
    "\n",
    "    questions.append({\n",
    "        \"section\": section[\"title\"],\n",
    "        \"summary\": parsed.get(\"summary\", \"\"),\n",
    "        \"questions\": parsed.get(\"questions\", []),\n",
    "    })\n",
    "    break\n",
    "\n",
    "# flatten questions for quizzing\n",
    "flat_questions = []\n",
    "\n",
    "for entry in questions:\n",
    "    section_title = entry[\"section\"]\n",
    "    for question in entry[\"questions\"]:\n",
    "        flat_questions.append({\n",
    "            \"section\": section_title,\n",
    "            \"question\": question\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173367b7",
   "metadata": {},
   "source": [
    "### Quiz Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3400fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nQuiz Time! Please answer the following:\\n\")\n",
    "\n",
    "for i, q in enumerate(flat_questions):\n",
    "    print(f\"Q{i+1} ({q['section']}): {q['question']}\")\n",
    "\n",
    "print(\"\\nNow let's evaluate your answers!\\n\")\n",
    "\n",
    "for i, q in enumerate(flat_questions):\n",
    "    user_answer = input(f\"Answer for Q{i+1}: \")\n",
    "\n",
    "    # Find matching section text from original `sections`\n",
    "    matching_section = next((s for s in sections if s[\"title\"] == q[\"section\"]), None)\n",
    "\n",
    "    grading_prompt = f\"\"\"\n",
    "You are an AI tutor. Evaluate the student's answer to the following question using a 0 to 5 scale.\n",
    "\n",
    "Score Criteria:\n",
    "- 0: Completely incorrect or off-topic\n",
    "- 1 to 2: Partially correct, major gaps or confusion\n",
    "- 3 to 4: Mostly correct, minor omissions or errors\n",
    "- 5: Fully correct, clear, and complete\n",
    "\n",
    "Respond in this JSON format only:\n",
    "\n",
    "{{\n",
    "  \"score\": number between 0 and 5,\n",
    "  \"feedback\": \"A short, friendly explanation that sounds like you're speaking directly to the student. Encourage them or gently correct misunderstandings.\"\n",
    "}}\n",
    "\n",
    "Section title: {q['section']}\n",
    "Section content:\n",
    "{matching_section['text'] if matching_section else 'Unavailable'}\n",
    "\n",
    "Question: {q['question']}\n",
    "Student's answer: {user_answer}\n",
    "\"\"\".strip()\n",
    "\n",
    "    try:\n",
    "        response = client.generate(model=model, prompt=grading_prompt)\n",
    "        print(f\"\\nGemma's Feedback for Q{i+1}:\\n{response['response']}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error grading Q{i+1}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
